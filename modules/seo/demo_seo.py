#!/usr/bin/env python3
"""
SEO Demo
SEO Ê®°ÂùóÊºîÁ§∫ÔºåÊîØÊåÅ Gemini Âíå OpenAI LLM Êèê‰æõÂïÜ
"""

import asyncio
import os
import sys
import json
from datetime import datetime
from dotenv import load_dotenv

# Add project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

# Load environment variables
load_dotenv()

def get_llm_client(provider: str = None):
    """Get LLM client for specified provider"""
    if provider is None:
        # Auto-detect from available API keys
        if os.getenv('GEMINI_API_KEY'):
            provider = 'gemini'
        elif os.getenv('OPENAI_API_KEY'):
            provider = 'openai'
        else:
            print("‚ùå No LLM API keys found in .env file")
            return None
    
    print(f"ü§ñ Using LLM Provider: {provider.upper()}")
    
    if provider.lower() == "gemini":
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            print("‚ùå Gemini API key not found. Set GEMINI_API_KEY in your .env file")
            return None
        
        try:
            import google.generativeai as genai
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel("gemini-2.0-flash-lite")
            print("‚úÖ Gemini LLM client initialized successfully")
            return model
        except ImportError:
            print("‚ùå Google Generative AI package not installed. Install with: pip install google-generativeai")
            return None
        except Exception as e:
            print(f"‚ùå Failed to initialize Gemini LLM client: {e}")
            return None
    
    elif provider.lower() in ["openai", "gpt"]:
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            print("‚ùå OpenAI API key not found. Set OPENAI_API_KEY in your .env file")
            return None
        
        try:
            import openai
            client = openai.AsyncOpenAI(api_key=api_key)
            print("‚úÖ OpenAI LLM client initialized successfully")
            return client
        except ImportError:
            print("‚ùå OpenAI package not installed. Install with: pip install openai")
            return None
        except Exception as e:
            print(f"‚ùå Failed to initialize OpenAI LLM client: {e}")
            return None
    
    else:
        print(f"‚ùå Unsupported LLM provider: {provider}")
        return None

def interactive_select_provider():
    """Interactive LLM provider selection"""
    print("\nü§ñ LLM Provider Selection")
    print("=" * 40)
    
    providers = []
    if os.getenv('GEMINI_API_KEY'):
        providers.append(('GEMINI', 'gemini-2.0-flash-lite'))
    if os.getenv('OPENAI_API_KEY'):
        providers.append(('OPENAI', 'gpt-4-turbo-preview'))
    
    if not providers:
        print("‚ùå No LLM providers configured")
        return None
    
    print("Available LLM providers:")
    for i, (name, model) in enumerate(providers, 1):
        print(f"  {i}. {name} ({model})")
    print("  3. Auto-detect (recommended)")
    
    while True:
        try:
            choice = input("\nSelect LLM provider (1-3): ").strip()
            if choice == '3':
                print("‚úÖ Selected: Auto-detect")
                return providers[0][0] if providers else None
            elif choice in ['1', '2']:
                idx = int(choice) - 1
                if idx < len(providers):
                    selected = providers[idx][0]
                    print(f"‚úÖ Selected: {selected}")
                    return selected
            print("‚ùå Invalid choice. Please enter a number between 1 and 3")
        except (ValueError, IndexError):
            print("‚ùå Invalid choice. Please enter a number between 1 and 3")

async def demo_llm_seo_intelligence(llm_client, provider: str):
    """Demo LLM SEO Intelligence core features"""
    print(f"\nüéØ Demo: LLM SEO Intelligence Core Features ({provider.upper()})")
    
    # Import LLM intelligence
    from modules.seo.llm_intelligence import LLMSEOIntelligence
    from modules.seo.models import SEOOptimizationLevel, SEOContentType
    
    llm_intelligence = LLMSEOIntelligence(
        llm_client=llm_client,
        llm_provider=provider
    )
    
    test_content = "Working on new AI features for our productivity app"
    print(f"üìù Original Content: {test_content}")
    
    # Test different optimization modes
    optimization_modes = [
        ("Comprehensive Optimization Mode", "comprehensive"),
        ("Intelligent Optimization Mode", "intelligent"), 
        ("Adaptive Optimization Mode", "adaptive")
    ]
    
    for mode_name, mode in optimization_modes:
        print(f"\nüîß Testing {mode_name}...")
        
        try:
            result = await llm_intelligence.optimize_content(
                content=test_content,
                optimization_level=SEOOptimizationLevel.AGGRESSIVE,
                content_type=SEOContentType.TWEET,
                target_audience="startup founders",
                target_keywords=["AI", "productivity", "startup"]
            )
            
            if result:
                print(f"‚ú® Optimized Content: {result.optimized_content}")
                print(f"üìä Optimization Score: {result.optimization_score:.2f}")
                print(f"üöÄ Estimated Reach Improvement: {result.estimated_reach_improvement:.1f}%")
                if result.improvements_made:
                    print(f"üîß Key Improvements:")
                    for improvement in result.improvements_made[:2]:  # Show only top 2
                        print(f"  ‚Ä¢ {improvement}")
            else:
                print("‚ùå Optimization failed")
                
        except Exception as e:
            print(f"‚ùå {mode_name} failed: {e}")

async def demo_enhanced_seo_optimizer(llm_client, provider: str):
    """Demo enhanced SEO optimizer"""
    print(f"\nüéØ Demo: Enhanced SEO Optimizer ({provider.upper()})")
    
    try:
        from modules.seo.optimizer import EnhancedSEOOptimizer
        from modules.seo.models import SEOOptimizationRequest, SEOContentType, SEOOptimizationLevel
        
        # Create enhanced optimizer
        optimizer = EnhancedSEOOptimizer(
            twitter_client=None,
            config={'llm_optimization_mode': 'comprehensive'},
            llm_client=llm_client
        )
        
        test_content = "Our new feature helps developers save time and boost productivity"
        print(f"üìù Original Content: {test_content}")
        
        # Create optimization request
        request = SEOOptimizationRequest(
            content=test_content,
            content_type=SEOContentType.TWEET,
            optimization_level=SEOOptimizationLevel.AGGRESSIVE,
            target_keywords=["development", "productivity"]
        )
        
        # Create analysis context
        from modules.seo.models import SEOAnalysisContext
        context = SEOAnalysisContext(
            content_type=SEOContentType.TWEET,
            target_audience="software developers",
            niche_keywords=["development", "productivity", "tools"]
        )
        
        print("üéØ Target Audience: software developers")
        print("üîë Target Keywords: development, productivity")
        print("üè∑Ô∏è Niche Keywords: development, productivity, tools")
        
        print("\nü§ñ Testing LLM-Enhanced Optimization Modes...")
        
        # Test different optimization modes
        modes = ['comprehensive', 'intelligent', 'adaptive']
        
        for mode in modes:
            print(f"\nüîß Testing {mode.title()} Mode...")
            
            try:
                # Set optimization mode
                optimizer.llm_config['llm_optimization_mode'] = mode
                
                # Perform optimization
                result = await optimizer.optimize_content_async(request, context)
                
                if result:
                    print(f"‚ú® Optimized Content: {result.optimized_content}")
                    print(f"üìä Optimization Score: {result.optimization_score:.2f}")
                    print(f"üöÄ Estimated Reach Improvement: {result.estimated_reach_improvement:.1f}%")
                    
                    if result.improvements_made:
                        print(f"üîß Key Improvements:")
                        for improvement in result.improvements_made[:2]:  # Show only top 2
                            print(f"  ‚Ä¢ {improvement}")
                else:
                    print("‚ùå Optimization failed")
                    
            except Exception as e:
                print(f"‚ùå {mode.title()} mode failed: {e}")
                
    except Exception as e:
        print(f"‚ùå Enhanced SEO optimizer demo failed: {e}")

async def main():
    """Main demo function"""
    print("üöÄ LLM-Enhanced SEO Module Demo")
    print("=" * 60)
    
    # Show available providers
    available = []
    if os.getenv('GEMINI_API_KEY'):
        available.append('GEMINI')
    if os.getenv('OPENAI_API_KEY'):
        available.append('OPENAI')
    
    print(f"\nüìã Available LLM Providers: {', '.join(available)}")
    
    # Interactive provider selection (only once)
    selected_provider = interactive_select_provider()
    if not selected_provider:
        print("‚ùå No LLM provider selected. Demo cancelled.")
        return
    
    # Get LLM client
    llm_client = get_llm_client(selected_provider)
    if not llm_client:
        print("‚ùå LLM client not available")
        return
    
    print("=" * 60)
    
    # Run core demos with the selected provider
    await demo_llm_seo_intelligence(llm_client, selected_provider)
    await demo_enhanced_seo_optimizer(llm_client, selected_provider)
    
    print("\n" + "=" * 60)
    print("üéâ LLM-Enhanced SEO Demo Completed!")
    
    print("\nüîß Quick Integration Guide:")
    print("1. Replace your existing SEOOptimizer with EnhancedSEOOptimizer")
    print("2. Pass your LLM client when initializing the services")
    print("3. Configure optimization modes in your config")
    
    print("\nüí° Key Benefits:")
    print("‚úÖ Intelligent keyword integration that maintains natural flow")
    print("‚úÖ Context-aware hashtag optimization")
    print("‚úÖ Engagement-focused content enhancement")
    print("‚úÖ Multiple optimization strategies (traditional, hybrid, intelligent)")
    print("‚úÖ Backward compatibility with existing code")
    
    print(f"\nü§ñ LLM Provider Used: {selected_provider.upper()}")
    print("‚úÖ Automatic provider detection and parsing")
    print("‚úÖ Single provider selection")

if __name__ == "__main__":
    asyncio.run(main()) 